{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prebacivanje epuba u txt te korištenje regexa za čišćenje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "import re\n",
    "from ebooklib import epub\n",
    "def epub2thtml(epub_path):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    chapters = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            chapters.append(item.get_content())\n",
    "    return chapters\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "blacklist = [   '[document]',   'noscript', 'header',   'html', 'meta', 'head','input', 'script', 'xa0', 'n' ]\n",
    "# there may be more elements you don't want, such as \"style\", etc.\n",
    "\n",
    "def chap2text(chap):\n",
    "    output = ''\n",
    "    soup = BeautifulSoup(chap, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            output += '{} '.format(t)\n",
    "    return output\n",
    "\n",
    "def thtml2ttext(thtml):\n",
    "    Output = []\n",
    "    for html in thtml:\n",
    "        text =  chap2text(html)\n",
    "        Output.append(text)\n",
    "    return Output\n",
    "\n",
    "def epub2text(epub_path):\n",
    "    chapters = epub2thtml(epub_path)\n",
    "    ttext = thtml2ttext(chapters)\n",
    "    return ttext\n",
    "\n",
    "def listToString(s):\n",
    "    str1 = \"\"\n",
    "    for elem in s:\n",
    "        str1 += elem\n",
    "    return str1\n",
    "\n",
    "out=epub2text('brlicmazuranic_basne.epub')\n",
    "outString = listToString(out)\n",
    "plainText=re.sub(r'[~%&\\\\<>?#]+(r|n|xa0)',\"\",outString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28502"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basneTxt = open(\"basne\",\"w\")\n",
    "basneTxt.write(str(plainText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basne.txt Spreman za  korištenje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "with io.open('basne', encoding='utf-8') as fin:\n",
    "    text=fin.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl = int(80*len(text)/100)\n",
    "train = text[:spl]\n",
    "test = text[spl:]\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3 #trigram\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treniranje `N-GRAM` modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "model = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generiranje jezika korištenjem `N-GRAM` jezičnog modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(model, num_words, random_seed=42):\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed = random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobrotvor soko ptičicu hrani.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model,20,random_seed=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mu dadem dobar zalogaj!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model,10, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spremanje modela u serijalizator objekta `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "with (open('ngram_model.pkl', 'wb')) as fout:\n",
    "    pickle.dump(model,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učitavanje modela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open('ngram_model.pkl', 'rb')) as fin:\n",
    "    model_loaded = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija koja generira 10 random rečenica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate10(model):\n",
    "    import random\n",
    "    x = 0\n",
    "    while(x<10):\n",
    "        a = random.randrange(1,20)\n",
    "        b = random.randrange(1,100)\n",
    "        sent = generate_sent(model,a,random_seed=b)\n",
    "        print(sent)\n",
    "        x+=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "šegrt hlapić i danas je među najomiljenijim dječjim knjigama, oba\n",
      "hladom mališ se pati, krilca ga gola ne mogu dić.\n",
      "pas započme govor lijep\n",
      "biva, ele, soko ovog\n",
      "će, al na svoju pustu nesreću ili sreću nikuda iz svoje kaljuže ne kreću\n",
      "] titra, a veliko zvijere!\n",
      "hladom mališ se pati, krilca ga\n",
      "\n",
      "u starogrčkoj arhitekturi sa karakterističnim užlijebljenim stupovima (drugi stilovi\n",
      "a što mi ga radiš?\n"
     ]
    }
   ],
   "source": [
    "generate10(model_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
